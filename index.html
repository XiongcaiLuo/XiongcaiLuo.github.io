<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>西瓜的木屋</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="西瓜的木屋">
<meta property="og:url" content="http://luoxc.com/index.html">
<meta property="og:site_name" content="西瓜的木屋">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="西瓜的木屋">
  
    <link rel="alternate" href="/atom.xml" title="西瓜的木屋" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="index.html" id="logo">西瓜的木屋</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="index.html" id="subtitle">记录关于机器学习、智能逻辑、人文社科方面的读书心得</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="index.html">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://luoxc.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-standard-varariable" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2018/01/06/standard-varariable/" class="article-date">
  <time datetime="2018-01-06T15:39:02.000Z" itemprop="datePublished">2018-01-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2018/01/06/standard-varariable/">特征标准化与条件数</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="standardize-variable-and-conditon-number"><a href="#standardize-variable-and-conditon-number" class="headerlink" title="standardize variable and conditon number"></a>standardize variable and conditon number</h2><hr>
<h3 id="何时standardize"><a href="#何时standardize" class="headerlink" title="何时standardize?"></a>何时standardize?</h3><p>减去mean后的截距的一个有趣看法：相当于每个predictor取值为mean之后，Y的期望；如果没有去中心化，那么解释就是所有predictor为0时的，Y的取值，没有那么自然了。</p>
<p>对于LR，不归一化，某些取值较大的predictor，他们的weight在学习的时候波动会非常距离，而且学习的时候方向会偏向这些predictor，导致其它的权重没有充分学习。<br>$$h(x) = \frac{1}{1+e^{-(wx+b)}}$$</p>
<p>loss function:<br>$$L = \frac{1}{n}\sum_{i=1}^n - y_i log h(x_i) - (1-y_i)log(1-h(x_i))$$</p>
<p>求梯度后：<br>$$\frac{\partial L}{\partial w} = \frac{1}{n}\sum_{i=1}^n (y_i-h(x_i))x_i $$</p>
<p>则更新公式为：<br>$$w^{(t+1)} = w^{(t)} - \eta \cdot \frac{1}{n}\sum_{i=1}^n (y_i-h(x_i))x_i $$<br>当某一维特征过大时，会导致相应的权重变化剧烈，训练过程不稳定，也导致其它的参数无法充分的学习（Loss function的变化被该特征dominate了）。</p>
<p>同样，对于线性回归$y = wx+b$, $\frac{\partial y}{\partial w} = x$,可知梯度更新如下：$$ w^{(t+1)} = w^{(t)}  - \eta  \cdot \frac{1}{n}\sum_{i=1}^n x_i$$<br>这个，若某一维度的特征取值数量级过大，会产生更严重的不稳定。从病态矩阵角度讲，这时的条件数也极可能比较大，导致求解不稳定</p>
<p>对于LR，是否可以认为它的权重就是相对重要性？如果对某一个predictor的取值进行放缩（比如单位换算），若是相对重要性，那系数应该不变才对吧？所以，相对重要性，应该是将这些Predictor都进行标准化(归一化)，才能说这些系数是相对重要性吧？</p>
<p>非中心化，可能会带来collinear的问题：<a href="https://stats.stackexchange.com/questions/60476/collinearity-diagnostics-problematic-only-when-the-interaction-term-is-included#61022" target="_blank" rel="external">https://stats.stackexchange.com/questions/60476/collinearity-diagnostics-problematic-only-when-the-interaction-term-is-included#61022</a><br><img src="/2018/01/06/standard-varariable/cond1.png" alt="cond1"></p>
<p><img src="/2018/01/06/standard-varariable/cond2.png" alt="cond2"></p>
<p><strong>条件数</strong><br>参考资料：<br><a href="https://www.cnblogs.com/daniel-D/p/3219802.html" target="_blank" rel="external">https://www.cnblogs.com/daniel-D/p/3219802.html</a><br><a href="http://blog.csdn.net/pipisorry/article/details/52241141" target="_blank" rel="external">http://blog.csdn.net/pipisorry/article/details/52241141</a></p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li>（need to read）<a href="http://andrewgelman.com/2009/07/11/when_to_standar/" target="_blank" rel="external">http://andrewgelman.com/2009/07/11/when_to_standar/</a></li>
<li><a href="https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia" target="_blank" rel="external">https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2018/01/06/standard-varariable/" data-id="cjc3iqp8c000qu15dmxljrdta" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-gan-basic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2018/01/06/gan-basic/" class="article-date">
  <time datetime="2018-01-06T14:50:04.000Z" itemprop="datePublished">2018-01-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2018/01/06/gan-basic/">GAN的基本原理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="GAN-简介"><a href="#GAN-简介" class="headerlink" title="GAN 简介"></a>GAN 简介</h2><h3 id="GAN的工作原理"><a href="#GAN的工作原理" class="headerlink" title="GAN的工作原理"></a>GAN的工作原理</h3><p>generator 和 discriminator相互博弈：</p>
<ul>
<li>discrimiator最大化真实样例与generator样例之间的差异</li>
<li>generator根据discriminator“反馈的指导信息”，更新参数，生成“更靠谱”的样例，减小与真实样例的差异。</li>
</ul>
<p><strong>Minimax Game:</strong><br>$$<br>    min_G\; max<em>D\; V(G, D)<br>$$<br><strong>在origin GAN中：</strong><br>$$<br>    V = E</em>{x\sim P<em>{data}}[logD(x)] + E</em>{x \sim P_G}[log(1-D(x))]<br>$$<br>一般而言，G是neural network, 它从一个先验分布$P<em>z$,生成x,上式写成：<br>$$<br>    V = E</em>{x\sim P<em>{data}}[logD(x)] + E</em>{z \sim P_z}[log(1-D(G(z)))]<br>$$</p>
<h3 id="GAN的应用示例"><a href="#GAN的应用示例" class="headerlink" title="GAN的应用示例"></a>GAN的应用示例</h3><p>目前，Tensorflow 1.4已经提供了一些gan的实现，在tf.contrib.gan中；另外，有很多开源的GAN的实现。（示例略，可以参加mnist上的各种实验和DCGAN、WGAN等生成的图片）</p>
<h2 id="GAN与ML"><a href="#GAN与ML" class="headerlink" title="GAN与ML"></a>GAN与ML</h2><h3 id="LR判别模型"><a href="#LR判别模型" class="headerlink" title="LR判别模型"></a>LR判别模型</h3><p>样本实例集合：$D = {(x^i, y^i)}<em>{i=1}^n$<br>利用最大似然(ML), 求解判别模型：$h</em>{\theta}(x) = \frac{1}{1+e^{-\theta^T x}} $<br>$$<br>\theta^<em> = arg\ max\ \frac{1}{n}\sum<em>{i=1}^n y^i log\ h</em>\theta(x^i) + (1-y^i)log(1-h<em>\theta(x^i)) \<br>=  arg\ max\ \frac{1}{n} \sum</em>{y^i=1}log\ h<em>{\theta}(x^i) + \sum</em>{y^j=0} log(1-h_\theta(x^j))\<br>=  arg\ max\ \frac{|D_1|}{n} \frac{1}{|D<em>1|} \sum</em>{D<em>1}log\ h</em>{\theta}(x^i) + \frac{|D_0|}{n} \frac{1}{|D<em>0|} \sum</em>{D<em>0}log\ h</em>{\theta}(x^j)\<br>= arg\ max\ P(y=1)E<em>{x\sim P(x|y=1)}[log h</em>\theta(x)] +  P(y=0)E<em>{x\sim P(x|y=0)}[log (1-h</em>\theta(x))]<br>$$<br>事实上，当假设空间$h<em>\theta(x)$有足够强的表征能力，（比如真实分布确实由LR模型生成，或者$h</em>\theta$是深层神经网络，可以表征任意函数）；通过求导，可以得到最优解为：<br>$$<br>    h^</em><em>\theta(x) = \frac{P(y=1)P(x|y=1)}{P(y=1)P(x|y=1) + P(y=0)P(x|y=0)} \<br>    = \frac{P(x, y=1)}{P(x) } = P(y=1 | x)<br>$$<br>(额，貌似推理了一句废话，不过这个公式正说明，当我们采用ML或者cross entropy的时候，最优解正是后验概率（条件概率），前提是$h</em>\theta(x)$有足够强的表征能力。推导这个式子，也可以和后面推导$D^*$相互验证)<br>观察式子：</p>
<ul>
<li>$x^i $是正例， $h_\theta(x^i)$尽可能大，接近1</li>
<li>$x^j $是负例， $h_\theta(x^j)$尽可能小，接近0</li>
<li>或者添加负号，可以从极小化negative log loss的角度考虑。</li>
</ul>
<p>对于GAN而言，某种程度上，D是h:</p>
<ul>
<li>$x^i \sim P_{data}$, 是<strong>“正例”</strong>，判别器D应使得$D(x^i)$尽可能大，接近1，即极大化$log(D(x^i))$</li>
<li>$x^j \sim P_{G}$, 是<strong>“负例”</strong>，判别器D应使得$D(x^j)$尽可能小，接近0, 即极大化 $log(1-D(x^j))$</li>
<li>类似地，忽略先验概率，V函数定义为$$V = E<em>{x\sim P</em>{data} }[logD(x)] + E<em>{x \sim P</em>{G}}[log(1-D(x))] = E<em>{x\sim P</em>{data} }[logD(x)] + E_{z \sim P_z}[log(1-D(G(z)))] $$,  而$D^* = max_D\; V(G,D)$; （这里忽略$P(y)$,两类先验概率相等，正对应后面训练D时，进行相等数量的sample）</li>
</ul>
<p><strong>事实上，训练判别器D的过程，正是使用ML求解二分类问题</strong>：</p>
<ul>
<li>sample $x^1, x^2 \cdots x^n$ from $P_{data}(x)$, 作为正例</li>
<li>sample  $\tilde{x^1}, \tilde{x^2} \cdots \tilde{x^n}$ from $P_{G}(x)$ （实际是sample z）， 作为负例</li>
<li>利用最大似然求解$V = \frac{1}{n}\sum<em>{i=1}^n log\ D(x^i) + \frac{1}{n}\sum</em>{i=1}^n log(1-D(\tilde{x}^i)) $</li>
</ul>
<p>(同样的思想，有“NCE”， “negative sampling”)</p>
<h3 id="ori-GAN和ML分别衡量不同的divergency"><a href="#ori-GAN和ML分别衡量不同的divergency" class="headerlink" title="ori-GAN和ML分别衡量不同的divergency"></a><strong>ori-GAN和ML分别衡量不同的divergency</strong></h3><ul>
<li>ML 衡量生成模型与真实概率分布的KL距离</li>
<li>ori-GAN衡量JS距离</li>
</ul>
<h4 id="ML-and-KL-divergency"><a href="#ML-and-KL-divergency" class="headerlink" title="ML and KL divergency"></a>ML and KL divergency</h4><p>未知的真实分布：$P<em>{data}(x)$<br>样本实例集：$D = {x^i }</em>{i=1}^n$， 采样自$P_{data}(x)$<br>假设空间中的生成模型：$P<em>G(x;\theta)$来模拟$P</em>{data}(x)$<br>根据ML原则：</p>
<p>$$ \theta^* = arg\; max<em>{\theta} \;  \prod</em>{i=1}^n P<em>G(x^i;\theta) \ = arg\; max</em>{\theta} \; \frac{1}{n}\sum_{i=1}^n log\ P<em>G(x^i; \theta) \ \approx arg\; max</em>{\theta} \; E<em>{x\sim P</em>{data} [log  P<em>G(x; \theta)]} \ = arg\; max</em>{\theta} \; \int<em>x P</em>{data}(x)logP_G(x;\theta)dx - \int<em>x P</em>{data}(x)logP<em>{data}(x)dx \ = arg\; min</em>{\theta}\; KL(P_{data}(x)\ ||\ P_G(x;\theta) ) $$</p>
<p>所以，对生成模型采用ML原则，实际最小化KL距离。</p>
<h4 id="origin-GAN-and-JS-Divergency"><a href="#origin-GAN-and-JS-Divergency" class="headerlink" title="origin-GAN and JS Divergency"></a>origin-GAN and JS Divergency</h4><ol>
<li><strong>给定G, 求解$D^<em> = max_D V(G,D)$；此时$V(G,D</em>)$衡量$ P_{data}, P_G$之间JS divergency</strong></li>
</ol>
<p>$$<br>max_D\ V(G,D) =max_D\ \int<em>x[P</em>{data}(x) log D(x) + P<em>G(x)log(1-D(x))] dx \Rightarrow \  D^*(x) = \frac{P</em>{data}(x)}{P_{data}(x) + P_G(x)}<br>$$</p>
<p>类比前面的LR的最优解$h^<em>_\theta(x)$，$D^</em>$表示在先验概率相等的前提下，后验概率$P(x来自于真实data|x)$</p>
<p>此时，<br>$$<br>V(G,D^*) = \int<em>x[P</em>{data}(x) log \frac{P<em>{data}(x)}{P</em>{data}(x) + P_G(x)} + P<em>G(x)log(1-\frac{P</em>{data}(x)}{P_{data}(x) + P_G(x)})] dx \ =  \int<em>x[P</em>{data}(x) log \frac{P<em>{data}(x)}{(P</em>{data}(x) + P_G(x))/2} + P<em>G(x)log\frac{P</em>{G}(x)}{(P_{data}(x) + P<em>G(x))/2}] dx - 2log2\ = KL(P</em>{data}(x) || \frac{P_{data}(x) + P<em>G(x)}{2}) + KL(P</em>{G}(x) || \frac{P_{data}(x) + P<em>G(x)}{2}) - 2log2\ = 2JSD(P</em>{data}, P_G) - 2log2<br>$$</p>
<ol>
<li><strong>求解G使得 $G^<em> = min_G V(G, D^</em>) $</strong></li>
</ol>
<h4 id="GAN的训练过程"><a href="#GAN的训练过程" class="headerlink" title="GAN的训练过程"></a>GAN的训练过程</h4><p><img src="/2018/01/06/gan-basic/train_gan.png" alt="train_gan"><br>（<strong>GAN的完整训练过程</strong>。图片来自于“李宏毅 深度学习”课程）<br>(Ian Goodfellow, 在原始论文中改训练G为$-log(D(G(z)))$, 这个训练目标是从收敛的角度来考虑的)</p>
<h4 id="GAN的特别之处在哪里？"><a href="#GAN的特别之处在哪里？" class="headerlink" title="GAN的特别之处在哪里？"></a>GAN的特别之处在哪里？</h4><ul>
<li>ML的训练会可能很麻烦：采用显式的概率分布（模型空间可能不够准确）；采用隐式的概率推断会涉及比较复杂的方法</li>
<li>GAN提供了另外一种方案，它直接利用BP来优化概率分布距离的方法：求解generator和discriminator的minimax博弈。generator和discriminator都采用neural network，有足够强大的表征能力（给一个表征能力的实验）。</li>
<li>GAN提供了一个框架，可以将ML纳入进来，甚至可以按需设计其它的函数V（参见fGAN）</li>
</ul>
<p><strong>那么能否在GAN的框架下，将ML与原始GAN统一起来？能否使用其它的概率距离度量？</strong></p>
<h2 id="fGAN-GAN的统一框架"><a href="#fGAN-GAN的统一框架" class="headerlink" title="fGAN: GAN的统一框架"></a>fGAN: GAN的统一框架</h2><h3 id="f-divergency"><a href="#f-divergency" class="headerlink" title="f-divergency"></a>f-divergency</h3><p><strong>定义：</strong><br>$$D_f(P || Q) = \int_x q(x) f(\frac{p(x)}{q(x)})dx,\ 且f是convex, f(1)=0$$ </p>
<p><strong>例子：</strong></p>
<ul>
<li>$f = xlogx, D_f(P||Q) = KL(P||Q)$</li>
<li>$f = -logx, D_f(P||Q) = revserse\ KL(P||Q)$</li>
<li><p>$f=ulogu-(u+1)log(u+1), D_f(P||Q) =2JS(P||Q) - 2log2$</p>
</li>
<li><p>f=ulogu-(u+1)log(u+1), D_f(P||Q) =2JS(P||Q) - 2log2$</p>
</li>
</ul>
<h3 id="Fenchel-Conjugate"><a href="#Fenchel-Conjugate" class="headerlink" title="Fenchel Conjugate:"></a><strong>Fenchel Conjugate:</strong></h3><p>$$f^<em>(t) = \max\limits<em>{x \in Dom(f)} {xt-f(x)}$$<br>$$f(x) = \max\limits</em>{t \in Dom(f^</em>)} {xt-f^<em>(t)}$$<br>（注：$f^</em>(t)$也是convex, 它是一系列仿射函数的max）</p>
<p><strong>事实上，Fenchel Conjugate定义了“斜率（梯度）到截距”的一种映射</strong><br>当固定$t $,  $f^<em>(t) = \max\limits_{x \in Dom(f)} {xt-f(x)}$, 通过对x求导得到：$$t=  f’(x), \ f^</em>(t) = xf’(x) - f(x)$$<br>上式可以看做参数方程的形式定义了$f^<em>$，它的几何意义：对任意的x，作f(x)的切线，斜率为t, 与y的截距的负数为$f^</em>(t)$; 它定义了斜率和负截距的映射关系。</p>
<p><strong>重要的是，上述映射关系的对偶性质！</strong></p>
<h3 id="与GAN的联系"><a href="#与GAN的联系" class="headerlink" title="与GAN的联系"></a>与GAN的联系</h3><p>$$<br>    D_f(P||Q) = \int_x q(x) f(\frac{p(x)}{q(x)})dx\<br>    = \int<em>x q(x) \max\limits</em>{t\in dom(f^<em>)} { t\frac{p(x)}{q(x)} - f^</em>(t)} dx\<br>    \ge  \max\limits_{t\in dom(f^<em>)}  \int_x p(x)t dx -  \int_x q(x)f^</em>(t) dx<br>$$</p>
<p>这里，令D(x) = t, 上式的下界可以写作：<br>$$<br>     \max\limits_{D}  \int_x p(x)D(x)dx -  \int<em>x q(x)f^*(D(x)) dx \<br>     =  \max\limits</em>{D} { E<em>{x\sim p}[D(x)] - E</em>{x\sim q}[f^<em>(D(x))] }<br>$$<br>(事实上，如果D(x)表征能力足够强，最优解为$D^</em>(x) = f’(\frac{p(x)}{q(x)})$,但是这个无法直接求解 )<br>对于GAN而言：<br>$$<br>    D<em>f(P</em>{data}||P<em>{G})  \approx \max\limits</em>{D} { E<em>{x\sim P</em>{data}}[D(x)] - E_{x\sim P<em>G}[f^<em>(D(x))] }<br>$$<br>写成minimax形式：<br>$$ G^</em> = \arg \min\limits</em>{G}\max\limits_{D} V(G,D)$$</p>
<p><strong>按需挑选不同的f-divergency:</strong><br><img src="/2018/01/06/gan-basic/fgan_1.png" alt="fgan_1_"><br><img src="/2018/01/06/gan-basic/fgan_2.png" alt="fgan_2_"><br>(<strong>不同的f-divergency对应的GAN</strong>, 图片来自于论文 f-GAN)</p>
<h2 id="WGAN：解决收敛性问题"><a href="#WGAN：解决收敛性问题" class="headerlink" title="WGAN：解决收敛性问题"></a>WGAN：解决收敛性问题</h2><h3 id="origin-GAN面临的收敛问题"><a href="#origin-GAN面临的收敛问题" class="headerlink" title="origin-GAN面临的收敛问题"></a>origin-GAN面临的收敛问题</h3><p><strong>理想情况：D 指导$P<em>G$往真实分布$P</em>{data}$(dashed)运动</strong><br><img src="/2018/01/06/gan-basic/wgan_1.png" alt="fgan_1_"><br><strong>实际情况：D训练越好，完美区分，梯度消失，无指导能力</strong><br><img src="/2018/01/06/gan-basic/wgan_2.png" alt="fgan_2_"></p>
<p>考虑”parallel lines distribution”, 二维分布$P_{data}: (0, Z), 其中Z \sim U[0,1]$, $P_G: (\theta, Z)$:</p>
<ul>
<li>$JS(P_{data}, P_G) = |\theta|$</li>
<li>$KL(P_{data} || P_G) = KL(P<em>G || P</em>{data} ) = + \infty (\theta \ne 0), 0(\theta=0)$</li>
<li>Discriminator D往往能将$P_{data}, P_G$完美分开</li>
<li>如上图所示，在D看来，$d<em>0, d</em>{50}$的JSD都是log2; D没有动力，让$P_G$往“期望的方向”移动，会导致收敛问题</li>
<li>事实上，像生物进化一样，进化（比如眼睛）往往不是一蹴而就的；应该有更合适的度量方式，使得$P<em>G$向$P</em>{data}$“靠拢”（虽然此时JSD看来，generator并没有改善）</li>
</ul>
<h3 id="Earth-Mover’s-Distance"><a href="#Earth-Mover’s-Distance" class="headerlink" title="Earth Mover’s Distance"></a>Earth Mover’s Distance</h3><p><strong>定义：</strong>对于概率分布P,Q，average distance of a plan $\gamma$:<br>$$ B(\gamma) = \sum\limits_{x_p, x_q} \gamma(x_p, x_q) ||x_p, x<em>q|| $$<br>Earth Mover’s Distance:<br>$$ W(P,Q) = \min\limits</em>{\gamma \in \Pi} B(\gamma)$$<br>示意图如下：<br>本质上，$\gamma$就是一个联合概率，它的边缘分布分别为$P, Q$<br><img src="/2018/01/06/gan-basic/earth_mover.png" alt="earth_mover"><br>（<strong>Moving Plan</strong>, 图片来自于“李宏毅 深度学习”）<br>在上面的<strong>parallel line distribution</strong>例子里,</p>
<ul>
<li>$W(P_{data}, P_G) = |\theta|$</li>
</ul>
<h3 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h3><p>论文中证明，当我们采用Earth Mover’s Distance来度量$P_{data}, P<em>G$距离，相应的GAN形式如下(Kantorovich-Rubinstein duality, 来自论文“Optimal Transport: Old and New”)：<br>$$<br>    W(P</em>{data}, P<em>G) = \max\limits</em>{D \in 1-lipschitz} { E<em>{x\sim P</em>{data}}[D(x)] -  E<em>{x\sim P</em>{G}}[D(x)] }<br>$$<br>其中，<strong>1-lipschitz </strong>是指：<br>$$ ||D(x_1) - D(x_2)|| \le ||x_1 - x_2|| $$<br>该条件的限制，防止了D(x)的变化过于剧烈。这里，整个优化目标有点“返璞归真”的意思了。<br><strong>WGAN的论文中，使用weight-clipping近似1-lipschitz 条件</strong>：</p>
<ul>
<li>权重$|w| &gt; c \Rightarrow |w|=c$</li>
<li>实际使用的是<strong>k-lipschitz</strong><br><img src="/2018/01/06/gan-basic/wgan_3.png" alt="wgan_3_"></li>
<li>可以看到origin GAN 会存在梯度消失，无法有效指导$P_G$的方向</li>
<li>WGAN可以提供有效信息。</li>
<li>$W(P_{data}, P_G)$的值可以作为训练好坏的参考</li>
</ul>
<p><strong>improved WGAN</strong></p>
<p>将WGAN的1-lipschitz条件以惩罚项的形式引入：</p>
<p>​    $$W(P_{data}, P<em>G) = \max\limits</em>{D} { E<em>{x\sim P</em>{data}}[D(x)] -  E<em>{x\sim P</em>{G}}[D(x)] } - \lambda E<em>{x\sim P</em>{penalty}}[(||\nabla_x D(x)||-1)^2]$$</p>
<p>$P<em>{penalty}$的生成：对于$x \sim P</em>{data}, \tilde{x} \sim P<em>G$, 计算$x，\tilde{x}$之间的随机点，作为$x’ \sim P</em>{penalty}$</p>
<h3 id="GAN的家族"><a href="#GAN的家族" class="headerlink" title="GAN的家族"></a>GAN的家族</h3><table>
<thead>
<tr>
<th style="text-align:left">Modify the optimization of GAN</th>
<th style="text-align:right">Different structure from the original GAN</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fGAN</td>
<td style="text-align:right">Conditional GAN</td>
</tr>
<tr>
<td style="text-align:left">WGAN</td>
<td style="text-align:right">Semi-GAN</td>
</tr>
<tr>
<td style="text-align:left">Least-square GAN</td>
<td style="text-align:right">InfoGAN</td>
</tr>
<tr>
<td style="text-align:left">Loss Sensitive GAN</td>
<td style="text-align:right">BiGAN</td>
</tr>
<tr>
<td style="text-align:left">Energy-based GAN</td>
<td style="text-align:right">Cycle GAN</td>
</tr>
<tr>
<td style="text-align:left">Boundary-Seeking GAN</td>
<td style="text-align:right">IRGAN</td>
</tr>
<tr>
<td style="text-align:left">Unroll GAN</td>
<td style="text-align:right">VAE GAN</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:right">…</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2018/01/06/gan-basic/" data-id="cjc3iqp5r0004u15dt10o8yla" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-auto-encoder" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/31/auto-encoder/" class="article-date">
  <time datetime="2017-12-31T02:48:00.000Z" itemprop="datePublished">2017-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/31/auto-encoder/">auto_encoder</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/31/auto-encoder/" data-id="cjc3iqp6c0006u15dwdn5h9uk" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-optimization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/31/optimization/" class="article-date">
  <time datetime="2017-12-30T18:49:46.000Z" itemprop="datePublished">2017-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/31/optimization/">最优化方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>@(math)[最优化, 牛顿法, 梯度下降法, 拟牛顿法, 数值计算]</p>
<hr>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p><strong>核心思想：负梯度方向是函数值下降最快的方向</strong><br>$$x_{i+1} = x_i - \eta f^{(1)}(x_i)$$<br>其中，$\eta &gt; 0$是学习率, 需要设置和调整。</p>
<h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p><strong>核心思想：将函数$f(x)$进行泰勒展开，得到二阶多项式</strong>,如第$i$次迭代时：<br>$$f(x) = f(x_i) + \frac{f^{(1)}(x_i)}{1!}(x - x_i) + \frac{f^{(2)}(x_i)}{2!}(x-x_i)^2 + o((x-x_i)^2)$$<br>当$f(x)$取极值时，有$f^{(1)}(x) = 0$, 因此对上式求导，并舍弃高阶项，得到：<br>$$0 = f^{(1)}(x_i) +f^{(2)}(x_i)(x-x_i) $$<br>$$x = x_i - \frac{f^{(1)}(x_i)}{f^{(2)}(x<em>i)}$$<br>对于多元函数，相应的矩阵迭代形式如下：<br>$$x</em>{i+1} = x<em>i - H</em>{x<em>i}^{-1}\nabla</em>{x_i} f$$<br>其中$H$是海塞矩阵<br><strong>特点：</strong></p>
<ul>
<li>对于二次函数，或者比较接近二次的函数或者在极小值点附近，牛顿法比梯度下降法收敛的更快</li>
<li>对于一般函数，牛顿法可能导致计算发散不收敛。改进：<strong>阻尼牛顿法</strong>，在搜索方向$- H_{x<em>i}^{-1}\nabla</em>{x<em>i} f$ 上搜索合适的步长$\lambda$：$- \lambda H</em>{x<em>i}^{-1}\nabla</em>{x_i} f$ </li>
<li>对于高维特征，$H^{-1}$的计算代价将非常高昂; 可以令$-H^{-1}_k g_k = p<em>k$, 通过求解$H</em>{k}p_k = -g_k$ 得到步长$p_k$, 但是每次计算$H_k$代价仍然非常高</li>
</ul>
<p><strong>H提供的信息</strong><br>二阶导数是对曲率的衡量。对于步长为$\epsilon$,</p>
<ul>
<li>H为0：代价函数下降约$\epsilon$</li>
<li>H为负：代价函数下降大于$\epsilon$</li>
<li>H为正：代价函数下降小于$\epsilon$，甚至有可能增长<br><img src="/2017/12/31/optimization/hess.png" alt="hess"></li>
</ul>
<p><img src="/2017/12/31/optimization/eq1.png" alt="eq1"><br>当步长为$\epsilon$时，迭代<br><img src="/2017/12/31/optimization/eq2.png" alt="eq2"><br>此时，若$H$正定矩阵，那么最优步长<br><img src="/2017/12/31/optimization/eq3.png" alt="eq3"><br>最坏情况下，g与H的最大特征向量方向平行，此时步长为$\frac{1}{\lambda_{max}}$</p>
<p><strong>局部极值测试</strong></p>
<ul>
<li>$f’(x) = 0, H(x) &gt; 0$: 局部极小值</li>
<li>$f’(x) = 0, H(x) &lt; 0$: 局部极大值</li>
<li>$f’(x) = 0, H(x) = 0$: 不确定</li>
</ul>
<p><strong>条件数</strong><br>对于矩阵$A \in R^{n\times n}$, 若有特征值，那么定义条件数：<br>$$cond(A) = |\frac{\lambda<em>{max}}{\lambda</em>{min}} |$$<br>$H$是对称矩阵，一定有n个特征值(包含重数)。</p>
<ul>
<li>当条件数过大时，矩阵求逆会放大误差<ul>
<li>本身求逆不稳定</li>
<li>$H^{-1}g$会放大$g$的误差。</li>
</ul>
</li>
</ul>
<h3 id="拟牛顿法"><a href="#拟牛顿法" class="headerlink" title="拟牛顿法"></a>拟牛顿法</h3><h4 id="DFP算法"><a href="#DFP算法" class="headerlink" title="DFP算法"></a>DFP算法</h4><p>牛顿法中海塞矩阵的计算代价高昂，考虑用一个n阶矩阵$G_k$去近似代替$H_k^{-1} = H^{-1}(x<em>k)$<br>我们将f在点$x</em>{k+1}$展开：<br>$$<br>    f(x) = f(x<em>{k+1}) + g</em>{k+1}^T x<em>k + \frac{1}{2}(x - x</em>{k+1})^T H<em>{k+1}(x - x</em>{k+1}) \<br>    \nabla f(x) = g<em>{k+1} + H</em>{k+1}(x - x<em>{k+1} ) \<br>$$<br>这里，取$x = x</em>{k}$, 则<br>$$<br>    g<em>k =  g</em>{k+1} + H_{k+1}(x<em>k - x</em>{k+1} )<br>$$<br>令$y<em>k = g</em>{k+1} - g_k, \delta<em>k = x</em>{k+1} - x<em>k$, 则：<br>$$<br>    H</em>{k+1} \delta_k = y<em>k, 或\<br>    H</em>{k+1}^{-1} y_k = \delta_k<br>$$<br>称之为<strong>拟牛顿条件</strong>,给出了下面的迭代依据：</p>
<ul>
<li>使用正定矩阵$G<em>k$代替$H</em>{k}^{-1}$，且迭代求解$G_{k+1}$</li>
</ul>
<p>令$G_{k+1} = G_k + \Delta G = G_k + P_k + Q<em>k$ , 则$G</em>{k+1}y_k = G_k y_k + P_k y_k + Q_k y_k$, 若要满足<strong>拟牛顿条件</strong>，只需：<br>$$<br>     P_k y_k = \delta_k\<br>     Q_k y_k = -G_k y_k<br>$$<br>只需：<br>$$<br>\delta_k = \delta_k \frac{\delta_k^T y_k}{\delta_k^T y_k} =\frac{\delta_k \delta_k^T }{\delta_k^T y_k} y_k \<br>令P_k = \frac{\delta_k \delta_k^T }{\delta_k^T y_k} 即可\<br>同理: Q_k = -\frac{G_k y_k y_k^T G_k}{y_k^T G_k y_k}<br>$$<br><strong>DFP算法伪代码：</strong><br><img src="/2017/12/31/optimization/DFP.png" alt="DFP"></p>
<h4 id="BFGS算法"><a href="#BFGS算法" class="headerlink" title="BFGS算法"></a>BFGS算法</h4><p>原理同DFP，但是直接使用$B_k$来模拟$H_k$而不是$H<em>k^{-1}$<br>$$<br>B</em>{k+1} = B_k + \frac{y_k y_k^T}{y_k^T \delta_k} - \frac{B_k \delta_k \delta_k^T B_k}{\delta_k^T B_k \delta_k}<br>$$<br><strong>BFGS算法伪代码：</strong><br><img src="/2017/12/31/optimization/BFGS.png" alt="BFGS"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/31/optimization/" data-id="cjc3iqp7x000lu15dox9cre0h" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-unbias-estimator" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/31/unbias-estimator/" class="article-date">
  <time datetime="2017-12-30T18:43:18.000Z" itemprop="datePublished">2017-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/31/unbias-estimator/">无偏估计</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>Bessel’s correction</strong></p>
<ul>
<li>计算协方差的时候并不是除以N, 那是因为每一列的和为0，因此自由度为N-1<ul>
<li>解释bias来源：<a href="https://en.wikipedia.org/wiki/Bessel%27s_correction#Source_of_bias" target="_blank" rel="external">https://en.wikipedia.org/wiki/Bessel%27s_correction#Source_of_bias</a><ul>
<li>本质上就是样本均值(sample mean)与总体均值(population mean)不同。此时，样本方差总是比真实方差小</li>
</ul>
</li>
</ul>
</li>
<li>修正后，方差是无偏的，但标准差是有偏的。因为sqrt是上凸函数<ul>
<li>标准差无偏估计：<a href="https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation" target="_blank" rel="external">https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation</a></li>
<li>自由度：能独立变化的变量个数</li>
</ul>
</li>
<li>当真实均值给定(而不是从样本中计算)时候，除以N</li>
</ul>
<p><strong>sample var, population var</strong></p>
<ul>
<li><p>$\mu$: population mean（总体均值）</p>
</li>
<li><p>$\delta^2$: population variance</p>
</li>
<li><p>$\bar{x}$: sample mean(样本均值)</p>
</li>
<li><p>$s_n^2$: sample variance（n个样本方差）</p>
<p>可以将$\bar{x}, s_n^2$看做随机变量，它们是对$\mu, \delta^2$的估计。</p>
<p>对于$\bar{x}$有：$$ E[\bar{x}] = \mu, 无偏估计$$<br>$$ E[(\bar{x} - \mu)^2] = \frac{\delta^2}{n}$$<br>对于$s_n^2$有：<br>$$ E[s<em>n^2] = E[\frac{1}{n} \sum</em>{i=1}^n(x<em>i - \bar{x})^2]  = E[\frac{1}{n} \sum</em>{i=1}^n(x<em>i - \mu + \mu - \bar{x})^2] \ = E[\frac{1}{n} \sum</em>{i=1}^n(x_i - \mu)^2 + (\mu - \bar{x})^2 + 2(x<em>i-\mu)(\mu - \bar{x})] \ = \frac{1}{n} \sum</em>{i=1}^nE[(x_i-\mu)^2] + E[(\mu - \bar{x})^2 + 2(\bar{x}-\mu)(\mu - \bar{x})] \ = \delta^2 - E[(\mu- \bar{x})^2] = \delta^2 - \frac{\delta^2}{n}  = \frac{n-1}{n}\delta^2$$</p>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/31/unbias-estimator/" data-id="cjc3iqp8j000su15dgpqognus" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-norm-dist" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/31/norm-dist/" class="article-date">
  <time datetime="2017-12-30T18:40:59.000Z" itemprop="datePublished">2017-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/31/norm-dist/">正态分布</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="单变量正态分布"><a href="#单变量正态分布" class="headerlink" title="单变量正态分布"></a>单变量正态分布</h3><p><strong>定义：</strong> $p(x) = \frac{1}{\sqrt{2\pi}\delta}e^{-\frac{1}{2}(\frac{x-\mu}{\delta})^2}$</p>
<ul>
<li>$E(x) = \mu$, $D(x) = \delta^2$</li>
<li>$y = ax+b$ 是正态分布，其中a,b是常数<ul>
<li>$E(y) = a\mu+b,  D(y) = a^2\delta^2$</li>
</ul>
</li>
<li>$y = \sum_{i=1}^{n}x_i$, 且$x_i$都是正态分布时， $y$是正态分布？<ul>
<li>$E(y) = \sum_{i=1}^{n}\mu<em>i,  D(y) =\sum</em>{i=1}^{n}\delta_i^2 $</li>
</ul>
</li>
</ul>
<h3 id="多元正态分布"><a href="#多元正态分布" class="headerlink" title="多元正态分布"></a>多元正态分布</h3><p><strong>定义：</strong>当随机向量$X=\mu + B\epsilon$满足: $u$是n维常向量，$B$是n*m维矩阵， $\epsilon = [\epsilon_1, \epsilon_2…\epsilon_m]$的分量都是相互独立的标准正态分布时，称$X$满足多元正态分布。</p>
<ul>
<li>即$X$的每一维都能分解成某一共同的<strong>m个相互独立的标准正态分布的线性组合</strong></li>
<li>$E(X) = \mu, \Sigma = BB^T$</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/31/norm-dist/" data-id="cjc3iqp7t000iu15dwbbd5ouk" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-tf-tutorial" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/31/tf-tutorial/" class="article-date">
  <time datetime="2017-12-30T17:13:22.000Z" itemprop="datePublished">2017-12-31</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/31/tf-tutorial/">Tensorflow简明导论</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>该文主要来自于TensorFlow白皮书，摘录了重点，以备不时之需。</p>
<hr>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><a href="https://www.tensorflow.org/" target="_blank" rel="external">https://www.tensorflow.org/</a></li>
<li>TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</li>
</ul>
<h3 id="Basic-concepts"><a href="#Basic-concepts" class="headerlink" title="Basic concepts"></a>Basic concepts</h3><p><strong>Operations</strong>: abstract computation(add, matrix multiply)</p>
<ul>
<li>attributes: </li>
<li>inferred at graph-construction time</li>
</ul>
<p><strong>kernel</strong>: particular implementation of an operation on a particular type of device(GPU, CPU)</p>
<p><strong>Tensors</strong></p>
<ul>
<li>typed, multi-dimensional array</li>
<li>input or output of operations</li>
<li>reference counted, and deallocated while no references remain.</li>
</ul>
<p><strong>Variable</strong>: </p>
<ul>
<li><strong>special operations</strong>, return a handle to a persistent mutable tensor</li>
<li>“<strong>parameters</strong>“, survive across the whole session; updated as part of “Run”</li>
<li>should call “initializer” in a session.</li>
</ul>
<p><strong>placeholder</strong></p>
<ul>
<li>“inputs” of a machine learning problem</li>
<li>feed_dict of “Run”</li>
</ul>
<p><strong>Graph</strong></p>
<ul>
<li>represented the whole computation as a dataflow graph</li>
<li>node: Operation objects(add, multiply, etc.)</li>
<li>edge:  tensor</li>
</ul>
<p><strong>Session</strong>: </p>
<ul>
<li>used to enable Client to interact with TF sys, manage the “Graph” computation</li>
<li>“Extend” method: augment the graph managed by the session</li>
<li>“Run” method:  fetch names to be computed; feed tensors as input.</li>
<li>run the whole graph or a few distinct subgraphs once</li>
</ul>
<p><strong>角色分工</strong></p>
<ul>
<li><strong>Client</strong>: the user side with TF codes， use Session to interact with “master”</li>
<li><strong>Master</strong>: TF system role for scheduling</li>
<li><strong>Worker</strong>: managed by master, responsible for managing “Devices” and run the actual “Tasks”.</li>
<li><strong>Job and task:</strong> 实际的一次任务执行称为一个job，job由多个task(分布式环境下)构成，由workder实际执行；单机时，client, master, worker 在一个os process环境下 。</li>
<li><strong>Devices:</strong> 实际的运算实体（CPU， GPU等）<ul>
<li>device type and name</li>
<li>device name example:  “ /job:localhost/device:cpu:0”</li>
<li>device name example:  “/job:worker/task:17/device:gpu:3”<br><img src="/2017/12/31/tf-tutorial/single_distribute_structure.png" alt="single_distribute_structure"></li>
</ul>
</li>
</ul>
<h3 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h3><h4 id="single-device-execution"><a href="#single-device-execution" class="headerlink" title="single-device execution"></a>single-device execution</h4><ul>
<li>依据Graph的依赖关系执行</li>
<li>每个node维护一个dependency counter; 当counter为0时，进入ready queue等待执行</li>
<li>node s 执行完毕，将所有依赖s的下游node的counter减1</li>
</ul>
<h4 id="Multi-device-execution"><a href="#Multi-device-execution" class="headerlink" title="Multi-device execution"></a>Multi-device execution</h4><p><strong>Node placement</strong></p>
<ul>
<li>核心：基于cost model进行simulation, 将node放置在合适的device上</li>
<li>cost model:<ul>
<li>input,output  tensors’ sizes</li>
<li>computation time</li>
</ul>
</li>
<li>simulation:<ul>
<li>使用贪心策略，依据Graph dependency，依次决定nodes的放置。</li>
<li>对于Node s，考虑s所有可行的devices, 依据下面两条决定：<ul>
<li>comunication time (if has): 可能的传输时间，如跨设备或分布式</li>
<li>cost model<br><strong>Cross-device comunication</strong></li>
</ul>
</li>
</ul>
</li>
<li>vertex-centric partiton.</li>
<li>在每个device上增加特殊节点：”Send”, “Receive”<ul>
<li>隔离：所有跨设备的通信交由Send和Receive来处理，包括同步等。</li>
<li>节省内存：在同一设备上多个节点依赖同一个tensor,只需要Receive管理一份，大大减少传输量和内存占用。</li>
</ul>
</li>
</ul>
<p><img src="/2017/12/31/tf-tutorial/multi_device_commu.png" alt="multi_device_commu"></p>
<h4 id="distributed-execution"><a href="#distributed-execution" class="headerlink" title="distributed execution"></a>distributed execution</h4><p>大部分执行机制同“Multi-device execution”</p>
<h4 id="Fault-Tolerance"><a href="#Fault-Tolerance" class="headerlink" title="Fault Tolerance"></a>Fault Tolerance</h4><p><strong>出错检测</strong></p>
<ul>
<li>Send, Recieve 通信报错</li>
<li>心跳机制检测</li>
</ul>
<p><strong>check-point 机制</strong></p>
<ul>
<li>Variable: 连接到Save node和Restore node<ul>
<li>每隔一定周期，Save node对variable进行持久化</li>
<li>恢复时，只在restart的第一次迭代时，将值赋给Variable</li>
</ul>
</li>
</ul>
<h3 id="Gradient-Computation"><a href="#Gradient-Computation" class="headerlink" title="Gradient Computation"></a>Gradient Computation</h3><p>TF提供自动的符号梯度计算</p>
<ul>
<li>[db,dW,dx] = tf.gradients(C, [b,W,x])<ul>
<li>extending the computation graph</li>
<li>backtracks from target C to source I, add “partial gradient node” to the Graph</li>
<li>梯度的计算不仅依赖”partial gradient nodes”,还依赖前向过程的input和output（图中灰色线），会导致大量tensor不能释放，占用存储<ul>
<li>更复杂的启发式规则，决定图计算顺序</li>
<li>recomputing tensor，而不是存储</li>
<li>将较长生存周期的tensor交换到cpu memory, 释放Gpu memory.<br><img src="/2017/12/31/tf-tutorial/gradient_graph.png" alt="gradient_graph"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Partial-Execution"><a href="#Partial-Execution" class="headerlink" title="Partial Execution"></a>Partial Execution</h3><p>TF支持执行subgraph, 并且支持在任意地方指定input tensor. 比如debug的时候，人为指定某个tensor的值。如图所示：<br><img src="/2017/12/31/tf-tutorial/partial_excu.png" alt="partial_excu"></p>
<ul>
<li>feed: 指定替换的Input tensor 的 name[:port]; 如图中inputs={b}</li>
<li>fetch: 指定观测结果的output tensor的 name[:port];如图中outputs={f:0}</li>
<li>执行重写后的graph，其余无关节点不执行计算</li>
</ul>
<h3 id="Parallel-Techs"><a href="#Parallel-Techs" class="headerlink" title="Parallel Techs"></a>Parallel Techs</h3><h4 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h4><ul>
<li>允许Graph的不同部分异步执行。（Ready Queue）</li>
<li>Enqueue, Dequeue</li>
<li>example: prefetch data for some nodes from disk while other nodes are computing according the Graph.</li>
<li>grouping</li>
<li>FIFO queue, shuffle queue</li>
</ul>
<h4 id="Data-Parallel-Training"><a href="#Data-Parallel-Training" class="headerlink" title="Data Parallel Training"></a>Data Parallel Training</h4><p>复制model(part of the Graph)到不同的devices，然后并行执行。</p>
<ul>
<li>SGD: mini-batch的并行执行<br><img src="/2017/12/31/tf-tutorial/data_parallel.png" alt="data_parallel"></li>
</ul>
<h4 id="Model-Parallel-Training"><a href="#Model-Parallel-Training" class="headerlink" title="Model Parallel Training"></a>Model Parallel Training</h4><p>模型的不同部分（different portions of the Graph）在不同的devcies上并行，处理同一批数据</p>
<ul>
<li>deep LSTM<br><img src="/2017/12/31/tf-tutorial/model_parallel.png" alt="model_parallel"></li>
</ul>
<h4 id="Concurrent-Steps-for-Model-Computation-Pipelining"><a href="#Concurrent-Steps-for-Model-Computation-Pipelining" class="headerlink" title="Concurrent Steps for Model Computation Pipelining"></a>Concurrent Steps for Model Computation Pipelining</h4><p>在同一个device内部进行流水线执行。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/31/tf-tutorial/" data-id="cjc3iqp8u000xu15d7s3svpfc" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-information-history" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/30/information-history/" class="article-date">
  <time datetime="2017-12-30T15:52:27.000Z" itemprop="datePublished">2017-12-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/逻辑的引擎/">逻辑的引擎</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/30/information-history/">《信息简史》--信息的本质</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<p>　　该文主要来自于美国科普作家詹姆斯·格雷克的《信息简史》的摘要（他还写过一本畅销书《混沌：开创新科学》），观点非常深刻清晰，颇具启发性；前半部观点新奇，后半部观点深刻，深刻到我无法完全看懂，以至于看了多遍，仍没有自信以自己的语言来重构他的全部观点。不过，它可是完全勾起了我对<strong>信息论</strong>的兴趣，对香农的远见（还有书中描写的维纳的狭促）印象无比深刻，以至于屁颠地跑去找了香农信息论的原始论文阅读：《The Mathematical Theory of Communication》（通信的数学原理），看得似懂非懂意犹未尽（也可能自己的数学储备知识还不够，主要是关于马尔科夫链和随机过程的一些障碍）。另外，还发现了一本极好的书<a href="https://book.douban.com/subject/1789534/" target="_blank" rel="external">《Information Theory, Inference, and Learning Algorithms》</a>，作者是<a href="https://book.douban.com/search/David%20J.%20C.%20MacKay" target="_blank" rel="external">David J. C. MacKay</a>，只是可惜2017年被ESL缠斗太久，无暇去看。</p>
<p>　　另外，书中关于艾伦·图灵与香农的一段神交，蔡廷和科尔戈莫洛夫关于扩展熵的定义殊途同归，蔡廷关于随机性与熵与图灵的不可计算数的联系，哥德尔不完备性与海森堡不确定原理之间的关系，太多联想充斥在脑中。一种不经意的喜悦，夹杂着无知与渴求的感觉。</p>
<p>　　最后，顺便推荐这本图灵的传记<a href="https://book.douban.com/subject/10779604/" target="_blank" rel="external">图灵的秘密 : 他的生平、思想及论文解读</a>。只看了一小部分，等有空了一口气看完，再做笔记。等关于随机性、不可计算数、哥德尔不完备性、计算理论、信息论都有一定的根基了，再来改写这篇笔记，多写写自己的见解了。</p>
<h3 id="摘录"><a href="#摘录" class="headerlink" title="摘录"></a>摘录</h3><ul>
<li>而对它（信息）加以简化、精炼，并以比特度量后，人们发现信息几乎无处不在。香农的理论在信息与不确定性、信息与熵，以及信息与混沌之间架起了桥梁。</li>
</ul>
<ul>
<li><p>词典为文字的持久性提供了正式认定，它表明一个字词的意义来自于其他的字词。这意味着，所有的字词聚集到一起，就可以形成一种互相关联的结构，因为所有的字词都是由其它的字词来定义的。这种现象在口语文化中并不存在，因为在那里语言是不可见的。只有当印刷术以及词典使语言成为一个个凸起的字符，可以被细细查看时，人们才能逐渐认识到字词的意义是互相依存，甚至是循环定义的。这时，字词必须被当做字词来看待，不同于所代表的事物，代表的只是其它字词。</p>
</li>
<li><p>词汇是对共同经验的一种量度，而后者来源于互连通性。</p>
</li>
<li><p>威尔金斯正试图接近信息最纯粹、最一般的形式，而文字只不过是其中一个特例：因为我们必须意识到，一般说来，任何能够创造出有效的差异，可为某种感官所感知的东西，都足以作为表达思想的手段。</p>
</li>
<li><p>语言至此被视作服务于两种独立的功能，既是表达的工具，也是思维的工具。人们一般假定，其中思维在先。对于布尔来说，逻辑就是思维，是思维经过打磨和提纯的结果。</p>
</li>
<li><p>我的办公室里就有一部电话，不过更多的是用来展示。如果我想发条讯息的话，我可以使用发报机，或差一个童仆去跑腿就行了…… 人们在面对一种全新技术时通常会遭遇想象力失灵。人们对于电报已经很熟悉，但与之相关的经验却无法移用到电话这种新设备上来。</p>
</li>
<li><p>当可连通的电话数量超过了某个临界值时，其拓扑结构就发生了变化，而且这种变化来得异常迅速。社区性的电话网络出现了，其相互连通的功能由一种称为交换机的新型设备来管理。</p>
</li>
<li><p>如果把图灵机简化到只剩下一张有限的状态表以及一个有限的输入集，那么图灵机本身就可以用数来表示… 图灵给他的机器编码，就如同哥德尔给他的符号逻辑语言编码一样。如此这般，数据和指令之间区分就被消除了：说到底，它们都不过是数而已。每个可计算数，必定对应着一个机器编号。</p>
</li>
<li><p>任何用于生成公式的机械的流程，本质上都是一台图灵机。因此，任何形式体系中必然存在不可判定的命题。数学是不可判定的，其不完全性来源自不可计算性。</p>
</li>
<li><p>当数被拿来编码机器的行为时，悖论就会再次现身。这涉及不可避免的递归纠缠：被计算的实体与进行计算的实体纠缠到了一起，带来种种恶果…物理学同样新近遇到了类似的难题：海森堡不确定原理… 过去我们一直假定，在科学中，只要知道了宇宙在某一时刻的全部状态，我们就能把宇宙所有的未来状态都预测出来…但更为现代的科学却认为，当我们面对原子和电子时，我们无法知道它们的全部确切状态，因为我们所用的仪器本身就是有原子和电子构成的。</p>
</li>
<li><p>图灵和香农都在使用编码，只是图灵把指令编码成数，将十进制数编码成0和1，而香农是对基因、染色体、继电器和开关编码。他们的灵巧智慧都应用在了如何将一类事物映射到另一类事物（例如，代数函数与机器指令，逻辑运算与电路），也就是找出两类事物之间严格的对应关系上。<strong>在他们心智的武器库中，符号运算以及映射的思想占据着举足轻重的地位。</strong></p>
</li>
<li><p>在香农看来，一条讯息就像一个动力系统，它的未来走向会受到过去历史的影响。</p>
</li>
<li><p>计算一个系统（如热力学系统）所有可能组合，可以发现其中无序状态远多于有序状态… 因此，有序状态的熵低，出现概率也低。</p>
</li>
<li><p>熵就成了概率在物理学上的等价物：某一给定宏观状态的熵，就是它所对应的围观状态数目的对数。因此，热力学第二定律揭示的是，宇宙从可能性较小的（有序的）宏观状态演化为可能性较大的（无序的）宏观状态的趋势。</p>
</li>
<li><p>它（麦克斯韦的妖）能看见，热力学第二定律只是在统计意义上成立，而不是由某种物理原因所决定的。事实上，在分子水平，这条定律就会被随机地违背。而这个妖则是用具有目的性的行为替代了这种随机性。<strong>它用信息降低了熵</strong>。</p>
</li>
<li><p>神经系统本身的存在，就是依赖于能量的持续耗散。</p>
</li>
<li><p>信息不是免费的。麦克斯韦、汤姆森等人都默认知识是现成的–关于分子速度和轨迹的知识就直接摆在了这个妖的眼前。他们没有考虑到，获取这些信息是需要成本的… 信息是物理的。麦克斯韦妖则在两者之间架起了桥梁，它每处理一个粒子，就是做了一次信息与能量的转换。齐拉特发现，只要精确核算每次度量和记忆，这种转换也是可以精确计算的。</p>
</li>
<li><p>“我考虑的是，从一个集合中作出选择时会有多少信息产生– 这样一来，集合越大，产生的信息越多。而你考虑的是，集合越大，不确定性越高时，对于该情况的知识就越少，因而信息也就越少。”换句话说，H度量的是出人意料的程度。</p>
</li>
<li><p>我们都像麦克斯韦妖一样活动。生物体(organism)，顾名思义，时刻在组织(organize)…收发邮件，创作诗词，音乐，制造工具等。</p>
</li>
<li><p>讯息越有规律，就越可预测；越可预测，就越冗余；越冗余，含有的信息就越少。随机程度如何与含有多少信息其实是同一个问题。</p>
</li>
<li><p>为什么说$\pi$不是随机的呢？蔡廷给出了一个明确的回答：一个数只要是可计算的，即它能够被一个可定义的计算机程序生成，那它就不是随机的。因为，可计算性是随机性的一种度量。</p>
</li>
<li><p>柯尔莫哥洛夫描述了三种度量（信息的）途径：基于组合、基于概率，以及基于算法… 以避免考虑所有可能对象组成的系统时可能遇到的问题。这种途径关注对象本身。</p>
</li>
<li><p>当人或计算机从经验中学习时，他们是在使用归纳推理，从无规律的信息流里识别出规律来。从这个意义上说，科学定律其实就是一种数据压缩，而理论物理学家就像是一个非常聪明的编码算法。</p>
</li>
<li><p>所罗门洛夫感兴趣的是归纳推理：给定一个观察数据的序列，人们如何作出关于后续事件的最优预测？柯尔莫哥洛夫寻找的则是随机性的数学定义：通过掷硬币以相同概率生成的两个序列，说一个序列比另一个序列更随机是什么意思？而蔡廷试图借助图灵和香农的理论，找到另一条更深刻地认识哥德尔不完全性定理的途径，正如他后来所说，“将香农的信息论和图灵的可计算理论倒进调酒器里，然后用例晃动”。最终他们三人的答案都与最短程序的长度有关，与复杂性有关。</p>
</li>
<li><p>信息不是不具实体的抽象，而总是与物理载体相联系，因而也必须遵循物理定理…无论它是表现为石板上的一个刻记、打孔卡片上的一个孔洞，还是一个粒子的自旋，信息都不可能摆脱某种物理载体而独立存在… 兰道尔提出，只有不可逆的操作，才会导致熵的增加。</p>
<p>许多计算可以不耗费任何能量就能完成，而热量耗散也只有在擦除信息时才会发生。擦除是一种不可逆的逻辑操作… 遗忘需要功。</p>
</li>
</ul>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>作者简介：<a href="https://en.wikipedia.org/wiki/James_Gleick" target="_blank" rel="external">https://en.wikipedia.org/wiki/James_Gleick</a></li>
<li>chaos software: <a href="http://www.cs.sjsu.edu/~rucker/chaos.htm" target="_blank" rel="external">http://www.cs.sjsu.edu/~rucker/chaos.htm</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/30/information-history/" data-id="cjc3iqp7l000du15dw9i2s7mw" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-influence" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/12/30/influence/" class="article-date">
  <time datetime="2017-12-30T15:46:43.000Z" itemprop="datePublished">2017-12-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/人文的意义/">人文的意义</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/12/30/influence/">《影响力》摘要</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>该文来自于《影响力》一书，书有点冗长，适合速度；暂且摘录一些有用的tips。</p>
<h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><ul>
<li>互惠</li>
<li>承诺和一致</li>
<li>社会认同</li>
<li>喜好</li>
<li>权威</li>
<li>短缺</li>
</ul>
<h3 id="只言片语"><a href="#只言片语" class="headerlink" title="只言片语"></a>只言片语</h3><ul>
<li>我们容忍这种美中不足（指根据某些“启动特征”做出的自动反应），多半也因为我们没有更好的办法。如果不借助这些经验和公式，我们只会永远裹足不前– 站在原地分类、评价、比较–而可以让我们采取行动的时间却在毫不留情的逝去。<strong>当我们的生活空间变得越来越充满了刺激和复杂多变时，我们也必然越来越频繁地依赖捷径来应付这一切</strong>。</li>
<li>当人们有这种愿望、也有这个能力去对有关的信息进行分析时，他们更可能对这些信息做出有控制的反应；否则的话，更可能采取“咔嗒，哔”的反应方式…当人们觉得事不关己时，他们完全依赖“专家的话一定是对的”这一规则，说服他们的不是演讲本身，而是演讲者在教育领域的造诣和地位；而当人们会受到这一主张影响时，他们的态度就不一样了。</li>
<li><strong>对比原理</strong>影响我们对先后接触到的两件东西的差别的判断。比如中介让你先看很差但是价钱又稍高的房子。<h4 id="互惠原理"><a href="#互惠原理" class="headerlink" title="互惠原理"></a>互惠原理</h4></li>
<li>由于<strong>互惠原理</strong>的影响力，我们感到自己有义务在将来回报我们收到的恩惠、礼物、邀请等等。对这一类东西的接受往往与偿还的义务紧紧联系在一起… 我们人类社会发展成今天的样子，是因为我们的祖先学会了在一个以名誉作担保的义务偿还网络中分享他们的食物和技能。</li>
<li>著名法国人类学家马塞尔·毛斯在描述人类文明的送礼过程以及与此有关的社会压力时说过这样的话：<strong>给予是一种义务，接受是一种义务，偿还也是一种义务</strong>。</li>
<li>互惠原理的例子：埃塞俄比亚给墨西哥的捐款、商家的试用试吃服务、调查问卷附带的小礼品、甚至街边硬塞给你的礼物等。</li>
<li>一般来说，整个社会对不遵守互惠原理的人的确有一种发自内心的厌恶。为了避免被贴上像忘恩负义这一类的标签，即使是不公平的交换我们有时候也是愿意接受的。</li>
<li>互惠原理导致的<strong>拒绝–退让</strong>：如果他人对我们做出了让步，我们也有义务做出让步。因为妥协也可以是一个互惠的过程。</li>
<li>如果他人最初的提议是我们想要的，我们就接受它，但我们接受的只是这个提议本身，与他人的角色无关..<strong>.互惠原理指出恩惠必须用恩惠来报答，但并没有说诡计也必须用恩惠来回报</strong>。</li>
<li>那些反向破坏互惠原理的人–<strong>只给与却不给人回报的机会– 也会遭致人们的厌恶</strong>。<h4 id="承诺和保持一致"><a href="#承诺和保持一致" class="headerlink" title="承诺和保持一致"></a>承诺和保持一致</h4></li>
<li>在很多情况下保持一致都是一种很有益、很得体的行为；自相矛盾被认为是一种不良的品性。若果一个人的信仰、言辞、行为相互矛盾，这个人就会被看做优柔寡断、头脑混乱、两面三刀。而另一方面，高度的一致则是和坚强的个性和优越的智力联系在一起的，是逻辑、理性、稳定和诚实的核心。</li>
<li>一旦我们对一件事情做出了决定，固执地坚持这个决定就成了一种非常难得的奢侈，因为这意味着我们再也不用为这件事操心了。</li>
<li>这种从小的请求开始最终达到对大请求的依从的策略，叫做“<strong>入门策略</strong>”：一旦他同意了某个请求，他的态度就变了，会尽可能的去保持承诺和一致。</li>
<li><strong>一个承诺必须是积极的、公开的、经过努力才做出的、而且是人们自由选择的结果</strong>…做出一个承诺所需付出的努力越多，这个承诺对许诺者的影响就越大,要让这些人从内心深处对这个承诺负起责任来。<h4 id="社会认同原理"><a href="#社会认同原理" class="headerlink" title="社会认同原理"></a>社会认同原理</h4></li>
<li><strong>不确定性</strong>：当人们对自己的处境不是很有把握时，更有可能根据他人的行为来决定自己应该怎么办。<strong>相似性</strong>：与我们类似的人对我们最有影响力。</li>
<li>现象：当单独一个人看到门底冒烟时，75%的人报了警。然而同样的冒烟事件被一个三人小组看见时，报警的概率则降到了38%。但是，报警次数最少的时候还是当三人小组中有两人事先被告知要表现得若无其事的时候，这时候报警的概率降到了10%</li>
<li><strong>多元无知效应</strong>在陌生人之间表现得最为显著：当旁观者不能肯定他们的目击事件是否紧急，尤其是这群人互不相识时，不施以援手的可能性最大。</li>
<li>（<strong>当出现紧急事件时，）从人群中仅仅挑出一个人来，注视着他，指着他，直接对他说：“你，穿蓝夹克的先生，我需要帮助，请叫一辆救护车来。</strong>”</li>
<li><strong>维特效应</strong>：大量报到自杀事件，会导致自杀事件发生的概率。</li>
</ul>
<h4 id="权威"><a href="#权威" class="headerlink" title="权威"></a>权威</h4><ul>
<li>具有独立思考能力的成年人也会为了服从权威的命令而做出一些完全丧失理智的事情。<strong>在权威的强大压力面前，个人的抵抗是十分渺小的</strong>。</li>
<li>来自权威的信息在很多情况下都为我们提供了一条行动的捷径。如老师和父母。一方面是他们拥有更多的智慧，另一方面也是由于他们就是决定赏罚的人。</li>
<li>权威影响例子：电刑实验、R-ear眼药水</li>
<li>（抵抗权威影响）最基本的方法是对权威保持高度的警觉。有了这种警觉，同时也意识到权威是多么容易造假，我们自然会采取一种比较谨慎的态度。</li>
<li>问自己两个问题。<strong>第一，这个权威是不是真正的专家？第二，这个权威会不会对我们说真话</strong>？</li>
</ul>
<h4 id="短缺"><a href="#短缺" class="headerlink" title="短缺"></a>短缺</h4><ul>
<li>去爱一样东西的方法之一就是意识到它可能会失去。</li>
<li>稀缺的例子：有瑕疵的邮票、错版的硬币、被封禁的信息等。</li>
<li>具有讽刺意义的是，对这种人–如一些可疑的政治团体–来说，为了让人们接受他们的观点，最有效的策略不是去公开宣扬这些观点，而是故意让这些观点遭受官方的封杀，然后再把被封杀的消息公之于众。</li>
<li><strong>先拥有后失去的短缺威力更大</strong>。当经济条件和社会条件改善之后又发生短暂而急剧的倒退时，就是我们最有可能看到革命和动乱的时候。因此，在一个社会中，最容易揭竿而起的，并不是那些传统上受压迫最深的人，因为对他们来说，自己所受的压迫可能已经成了自然秩序的一部分。相反，革命者更可能是那些至少品尝过比较好的生活滋味的人。当他们亲身经历过并寄予厚望的经济上的和社会上的进步突然变得可望而不可及时，他们便会对这种进步产生比以前任何时候都更强烈的欲望，甚至不惜以暴力来保卫。</li>
</ul>
<h4 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h4><ul>
<li>他们（依从业者）真正的罪状，也是我们不能容忍的一点，是他们赚钱的方法威胁到了我们的捷径的可靠性。<strong>我们必须借助稳妥可靠的捷径和经验来应付令人眼花缭乱的现代生活，这不是一种奢侈，而是一种必要</strong>。而且随着生活步调的加快，这些经验和捷径会显得越来越重要。因此，当我们看到有人为了自己的私利而践踏这些规则时，应该义愤填膺地对他们进行反击和声讨。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/12/30/influence/" data-id="cjc3iqp7j000cu15der8og0z6" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-funny-equation-1-variance-decomposition" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="2017/09/17/funny-equation-1-variance-decomposition/" class="article-date">
  <time datetime="2017-09-17T05:51:46.000Z" itemprop="datePublished">2017-09-17</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="2017/09/17/funny-equation-1-variance-decomposition/">好玩的公式系列1：方差分解的联想</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在“A FIRST COURSE IN PROBABILITY”里，偶然看到如下的条件方差分解公式：<br>$$Var(X) = Var(E[X|Z])+ E_X[Var(X|Z)]$$<br>于是我换了变量名，一下子熟悉起来：<br><strong>$$Var(Y) = Var(E_Y[Y|X])+ E_X[Var(Y|X)] $$</strong></p>
<ul>
<li>在机器学习中，X看做特征，Y为目标；在统计里，X看做自变量，Y看做因变量</li>
<li>它表达了理想情况下，采用<strong>MSE准则</strong>，预测函数$Y=g(X)=E_Y[Y|X]$时的方差组成：<ul>
<li>可以解读为: $target_var =  captured_var + MSE$<ul>
<li>$ Var(E_Y[Y|X])$: $captured_var$, 表征预测模型捕获的方差。</li>
<li>$ E_X[Var(Y|X)] $：表征预测残差，此时的MSE只有噪声，没有模型偏差。</li>
<li>$R^2 = \frac{Var(E_Y[Y|X])}{Var(Y)} $: 统计学里称之为<strong>“决定系数”</strong>。$R^2$越接近1，则表明$Y$的方差几乎都被$g(X)$捕获，预测残差小，预测的效果好；也说明数据质量好，噪音小！在这种理想情况下($g(X) = E_Y[Y|X]$)，可以用$R^2$评估数据质量。</li>
</ul>
</li>
</ul>
</li>
<li><p>事实上，往往预测函数$Y=g(X)\  \neq E_Y[Y|X]$：</p>
<ul>
<li>预测函数不能有效捕获Y的方差，MSE增大：$captured_var &lt; Var(E_Y[Y|X])$，$MSE &gt; E_X[Var(Y|X)]$,<ul>
<li>MSE的误差来源包含两部分：固有噪声$E_X[Var(Y|X)]$（机器学习中称为<strong>方差variance</strong>）和模型误差（机器学习中称为<strong>偏差bias</strong>），具体见下文证明。</li>
<li>若$g(X)$太差，将导致模型偏差部分非常大！机器学习中称之为“<strong>欠拟合</strong>”，下面是可能的原因：<ul>
<li>数据量过小，不能有效的估计出$E[Y|X]$</li>
<li>特征太差，没有表征力（极端情况下X和Y独立，见下文分析）</li>
<li>假设空间容量不够大，没有$E_X[Y|X]$及其有效近似。（如采用线性拟合非线性数据）<ul>
<li>假设空间足够大，但是没有有效的搜索策略。（如nerual network高度非凸的搜索空间）</li>
</ul>
</li>
</ul>
</li>
<li>要防止在训练集上过度拟合$g(X)$：<ul>
<li>机器学习中称之为<strong>“过拟合”</strong>：在训练集上近乎完美的拟合数据，但在测试集上表现糟糕, 因为：</li>
<li>现实数据集往往是有限的、有噪声的<ul>
<li>数据有限：极有限的数据可能难以反应真实数据分布， $g(X)$可能会拟合出过于复杂但不真实的形状，它可能会造成方差和偏差都增大；</li>
<li>数据噪声：噪声往往来源于固有噪声、数据收集噪声(如生产系统上的各种错误导致label不正确)等。这里只考虑固有噪声，即Y并不是X的确定性函数（如MSE假设$y = f(x) + \delta, \ \delta \sim N(0, \sigma)$）。通常，完美拟合训练集，$g(X)$会拟合噪声的波动，导致函数过于复杂，极小的$\Delta x$，会带来极大的$\Delta g(x)$；即我们通常所说的“方差过大，导致过拟合”</li>
<li>一般而言，我们在减小偏差(解决欠拟合)时，要防范方差爆炸（防范过拟合），可以采取正则化,drop out，bagging等一系列措施。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>当$X$与$Y$独立时（即特征X太烂，无法表征目标Y）: </p>
<ul>
<li>公式右边退化为$Var(Y) + 0$<ul>
<li>预测函数将完全无法捕获$Y$的方差</li>
<li>MSE中的偏差部分将增大！（特征工程很重要）</li>
</ul>
</li>
</ul>
</li>
<li><p>如何更好的使$g(X)$逼近$E[Y|X]$呢？</p>
<ul>
<li>对于条件期望$E[Y|X]$, 若对于每一个可能的$X$, 都有足够多样本来估计Y的条件期望；之后的预测，就只需查表。显然，不符合现实。<ul>
<li>对每个点$X$我们无法得到足够样本，但是可以将X的空间分段，进行分段拟合；</li>
<li>分段拟合为防止过拟合，可以限定假设空间为3次自然样条。</li>
<li>KNN采用$g(x) = Avg(y_i\ |\ x_i \in N_k(x))$来近似$E[Y|X=x]$</li>
</ul>
</li>
</ul>
</li>
<li><p>在抽样理论中：可尝试使用随机变量$E_Y[Y|X]$ 代替$Y$来模拟$E[Y]$,减小抽样方差， 因为：</p>
<ul>
<li>$E_X[E_Y[Y|X]] = E[Y]$<ul>
<li>$Var(E_Y[Y|X]) \le Var(Y)$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>MSE预测：</strong>对于MSE损失函数$L = E[Y-g(X)]^2$的解为：$g(X) = E[Y|X]$<br><strong>引理：</strong> $$\forall g(X), E[(Y-g(X))^2 | X] = \<br> E[(Y- E[Y|X])^2 |X] + E[(E(Y|X) - g(X))^2|X] \<br> \ge  E[(Y- E[Y|X])^2 |X]$$</p>
<ul>
<li>$ E[(Y- E[Y|X])^2 |X] $：数据分布固有噪声,如高斯白噪声等。称之为方差variance。</li>
<li>$E[(E(Y|X) - g(X))^2|X] $:  模型误差部分，称之为偏差bias。如真实函数为二次，却用线性回归拟合。模型误差受限于假设空间的容量，也受限于在假设空间的搜索过程（可能是局部最小值，并不能得到最优的$E(Y|X)$）</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2017/09/17/funny-equation-1-variance-decomposition/" data-id="cjc3iqp5e0002u15dvfszlhga" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="page/2/">2</a><a class="extend next" rel="next" href="page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="categories/人文的意义/">人文的意义</a></li><li class="category-list-item"><a class="category-list-link" href="categories/机器的理智/">机器的理智</a></li><li class="category-list-item"><a class="category-list-link" href="categories/琐碎的胜利/">琐碎的胜利</a></li><li class="category-list-item"><a class="category-list-link" href="categories/逻辑的引擎/">逻辑的引擎</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="archives/2017/02/">February 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="2018/01/06/standard-varariable/">特征标准化与条件数</a>
          </li>
        
          <li>
            <a href="2018/01/06/gan-basic/">GAN的基本原理</a>
          </li>
        
          <li>
            <a href="2017/12/31/auto-encoder/">auto_encoder</a>
          </li>
        
          <li>
            <a href="2017/12/31/optimization/">最优化方法</a>
          </li>
        
          <li>
            <a href="2017/12/31/unbias-estimator/">无偏估计</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Finch Luo<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="index.html" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="fancybox/jquery.fancybox.css">
  <script src="fancybox/jquery.fancybox.pack.js"></script>


<script src="js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>