<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>GAN的基本原理 | 西瓜的木屋</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="GAN 简介GAN的工作原理generator 和 discriminator相互博弈：

discrimiator最大化真实样例与generator样例之间的差异
generator根据discriminator“反馈的指导信息”，更新参数，生成“更靠谱”的样例，减小与真实样例的差异。

Minimax Game:$$    min_G\; maxD\; V(G, D)$$在origin GA">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN的基本原理">
<meta property="og:url" content="http://luoxc.com/2018/01/06/gan-basic/index.html">
<meta property="og:site_name" content="西瓜的木屋">
<meta property="og:description" content="GAN 简介GAN的工作原理generator 和 discriminator相互博弈：

discrimiator最大化真实样例与generator样例之间的差异
generator根据discriminator“反馈的指导信息”，更新参数，生成“更靠谱”的样例，减小与真实样例的差异。

Minimax Game:$$    min_G\; maxD\; V(G, D)$$在origin GA">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/train_gan.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/fgan_1.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/fgan_2.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/wgan_1.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/wgan_2.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/earth_mover.png">
<meta property="og:image" content="http://luoxc.com/2018/01/06/gan-basic/wgan_3.png">
<meta property="og:updated_time" content="2018-01-06T15:28:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GAN的基本原理">
<meta name="twitter:description" content="GAN 简介GAN的工作原理generator 和 discriminator相互博弈：

discrimiator最大化真实样例与generator样例之间的差异
generator根据discriminator“反馈的指导信息”，更新参数，生成“更靠谱”的样例，减小与真实样例的差异。

Minimax Game:$$    min_G\; maxD\; V(G, D)$$在origin GA">
<meta name="twitter:image" content="http://luoxc.com/2018/01/06/gan-basic/train_gan.png">
  
    <link rel="alternate" href="/atom.xml" title="西瓜的木屋" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="../../../../css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="../../../../index.html" id="logo">西瓜的木屋</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="../../../../index.html" id="subtitle">记录关于机器学习、智能逻辑、人文社科方面的读书心得</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="../../../../index.html">Home</a>
        
          <a class="main-nav-link" href="../../../../archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="Flux RSS"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Rechercher"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://luoxc.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-gan-basic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="" class="article-date">
  <time datetime="2018-01-06T14:50:04.000Z" itemprop="datePublished">2018-01-06</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="../../../../categories/机器的理智/">机器的理智</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      GAN的基本原理
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="GAN-简介"><a href="#GAN-简介" class="headerlink" title="GAN 简介"></a>GAN 简介</h2><h3 id="GAN的工作原理"><a href="#GAN的工作原理" class="headerlink" title="GAN的工作原理"></a>GAN的工作原理</h3><p>generator 和 discriminator相互博弈：</p>
<ul>
<li>discrimiator最大化真实样例与generator样例之间的差异</li>
<li>generator根据discriminator“反馈的指导信息”，更新参数，生成“更靠谱”的样例，减小与真实样例的差异。</li>
</ul>
<p><strong>Minimax Game:</strong><br>$$<br>    min_G\; max<em>D\; V(G, D)<br>$$<br><strong>在origin GAN中：</strong><br>$$<br>    V = E</em>{x\sim P<em>{data}}[logD(x)] + E</em>{x \sim P_G}[log(1-D(x))]<br>$$<br>一般而言，G是neural network, 它从一个先验分布$P<em>z$,生成x,上式写成：<br>$$<br>    V = E</em>{x\sim P<em>{data}}[logD(x)] + E</em>{z \sim P_z}[log(1-D(G(z)))]<br>$$</p>
<h3 id="GAN的应用示例"><a href="#GAN的应用示例" class="headerlink" title="GAN的应用示例"></a>GAN的应用示例</h3><p>目前，Tensorflow 1.4已经提供了一些gan的实现，在tf.contrib.gan中；另外，有很多开源的GAN的实现。（示例略，可以参加mnist上的各种实验和DCGAN、WGAN等生成的图片）</p>
<h2 id="GAN与ML"><a href="#GAN与ML" class="headerlink" title="GAN与ML"></a>GAN与ML</h2><h3 id="LR判别模型"><a href="#LR判别模型" class="headerlink" title="LR判别模型"></a>LR判别模型</h3><p>样本实例集合：$D = {(x^i, y^i)}<em>{i=1}^n$<br>利用最大似然(ML), 求解判别模型：$h</em>{\theta}(x) = \frac{1}{1+e^{-\theta^T x}} $<br>$$<br>\theta^<em> = arg\ max\ \frac{1}{n}\sum<em>{i=1}^n y^i log\ h</em>\theta(x^i) + (1-y^i)log(1-h<em>\theta(x^i)) \<br>=  arg\ max\ \frac{1}{n} \sum</em>{y^i=1}log\ h<em>{\theta}(x^i) + \sum</em>{y^j=0} log(1-h_\theta(x^j))\<br>=  arg\ max\ \frac{|D_1|}{n} \frac{1}{|D<em>1|} \sum</em>{D<em>1}log\ h</em>{\theta}(x^i) + \frac{|D_0|}{n} \frac{1}{|D<em>0|} \sum</em>{D<em>0}log\ h</em>{\theta}(x^j)\<br>= arg\ max\ P(y=1)E<em>{x\sim P(x|y=1)}[log h</em>\theta(x)] +  P(y=0)E<em>{x\sim P(x|y=0)}[log (1-h</em>\theta(x))]<br>$$<br>事实上，当假设空间$h<em>\theta(x)$有足够强的表征能力，（比如真实分布确实由LR模型生成，或者$h</em>\theta$是深层神经网络，可以表征任意函数）；通过求导，可以得到最优解为：<br>$$<br>    h^</em><em>\theta(x) = \frac{P(y=1)P(x|y=1)}{P(y=1)P(x|y=1) + P(y=0)P(x|y=0)} \<br>    = \frac{P(x, y=1)}{P(x) } = P(y=1 | x)<br>$$<br>(额，貌似推理了一句废话，不过这个公式正说明，当我们采用ML或者cross entropy的时候，最优解正是后验概率（条件概率），前提是$h</em>\theta(x)$有足够强的表征能力。推导这个式子，也可以和后面推导$D^*$相互验证)<br>观察式子：</p>
<ul>
<li>$x^i $是正例， $h_\theta(x^i)$尽可能大，接近1</li>
<li>$x^j $是负例， $h_\theta(x^j)$尽可能小，接近0</li>
<li>或者添加负号，可以从极小化negative log loss的角度考虑。</li>
</ul>
<p>对于GAN而言，某种程度上，D是h:</p>
<ul>
<li>$x^i \sim P_{data}$, 是<strong>“正例”</strong>，判别器D应使得$D(x^i)$尽可能大，接近1，即极大化$log(D(x^i))$</li>
<li>$x^j \sim P_{G}$, 是<strong>“负例”</strong>，判别器D应使得$D(x^j)$尽可能小，接近0, 即极大化 $log(1-D(x^j))$</li>
<li>类似地，忽略先验概率，V函数定义为$$V = E<em>{x\sim P</em>{data} }[logD(x)] + E<em>{x \sim P</em>{G}}[log(1-D(x))] = E<em>{x\sim P</em>{data} }[logD(x)] + E_{z \sim P_z}[log(1-D(G(z)))] $$,  而$D^* = max_D\; V(G,D)$; （这里忽略$P(y)$,两类先验概率相等，正对应后面训练D时，进行相等数量的sample）</li>
</ul>
<p><strong>事实上，训练判别器D的过程，正是使用ML求解二分类问题</strong>：</p>
<ul>
<li>sample $x^1, x^2 \cdots x^n$ from $P_{data}(x)$, 作为正例</li>
<li>sample  $\tilde{x^1}, \tilde{x^2} \cdots \tilde{x^n}$ from $P_{G}(x)$ （实际是sample z）， 作为负例</li>
<li>利用最大似然求解$V = \frac{1}{n}\sum<em>{i=1}^n log\ D(x^i) + \frac{1}{n}\sum</em>{i=1}^n log(1-D(\tilde{x}^i)) $</li>
</ul>
<p>(同样的思想，有“NCE”， “negative sampling”)</p>
<h3 id="ori-GAN和ML分别衡量不同的divergency"><a href="#ori-GAN和ML分别衡量不同的divergency" class="headerlink" title="ori-GAN和ML分别衡量不同的divergency"></a><strong>ori-GAN和ML分别衡量不同的divergency</strong></h3><ul>
<li>ML 衡量生成模型与真实概率分布的KL距离</li>
<li>ori-GAN衡量JS距离</li>
</ul>
<h4 id="ML-and-KL-divergency"><a href="#ML-and-KL-divergency" class="headerlink" title="ML and KL divergency"></a>ML and KL divergency</h4><p>未知的真实分布：$P<em>{data}(x)$<br>样本实例集：$D = {x^i }</em>{i=1}^n$， 采样自$P_{data}(x)$<br>假设空间中的生成模型：$P<em>G(x;\theta)$来模拟$P</em>{data}(x)$<br>根据ML原则：</p>
<p>$$ \theta^* = arg\; max<em>{\theta} \;  \prod</em>{i=1}^n P<em>G(x^i;\theta) \ = arg\; max</em>{\theta} \; \frac{1}{n}\sum_{i=1}^n log\ P<em>G(x^i; \theta) \ \approx arg\; max</em>{\theta} \; E<em>{x\sim P</em>{data} [log  P<em>G(x; \theta)]} \ = arg\; max</em>{\theta} \; \int<em>x P</em>{data}(x)logP_G(x;\theta)dx - \int<em>x P</em>{data}(x)logP<em>{data}(x)dx \ = arg\; min</em>{\theta}\; KL(P_{data}(x)\ ||\ P_G(x;\theta) ) $$</p>
<p>所以，对生成模型采用ML原则，实际最小化KL距离。</p>
<h4 id="origin-GAN-and-JS-Divergency"><a href="#origin-GAN-and-JS-Divergency" class="headerlink" title="origin-GAN and JS Divergency"></a>origin-GAN and JS Divergency</h4><ol>
<li><strong>给定G, 求解$D^<em> = max_D V(G,D)$；此时$V(G,D</em>)$衡量$ P_{data}, P_G$之间JS divergency</strong></li>
</ol>
<p>$$<br>max_D\ V(G,D) =max_D\ \int<em>x[P</em>{data}(x) log D(x) + P<em>G(x)log(1-D(x))] dx \Rightarrow \  D^*(x) = \frac{P</em>{data}(x)}{P_{data}(x) + P_G(x)}<br>$$</p>
<p>类比前面的LR的最优解$h^<em>_\theta(x)$，$D^</em>$表示在先验概率相等的前提下，后验概率$P(x来自于真实data|x)$</p>
<p>此时，<br>$$<br>V(G,D^*) = \int<em>x[P</em>{data}(x) log \frac{P<em>{data}(x)}{P</em>{data}(x) + P_G(x)} + P<em>G(x)log(1-\frac{P</em>{data}(x)}{P_{data}(x) + P_G(x)})] dx \ =  \int<em>x[P</em>{data}(x) log \frac{P<em>{data}(x)}{(P</em>{data}(x) + P_G(x))/2} + P<em>G(x)log\frac{P</em>{G}(x)}{(P_{data}(x) + P<em>G(x))/2}] dx - 2log2\ = KL(P</em>{data}(x) || \frac{P_{data}(x) + P<em>G(x)}{2}) + KL(P</em>{G}(x) || \frac{P_{data}(x) + P<em>G(x)}{2}) - 2log2\ = 2JSD(P</em>{data}, P_G) - 2log2<br>$$</p>
<ol>
<li><strong>求解G使得 $G^<em> = min_G V(G, D^</em>) $</strong></li>
</ol>
<h4 id="GAN的训练过程"><a href="#GAN的训练过程" class="headerlink" title="GAN的训练过程"></a>GAN的训练过程</h4><p><img src="/2018/01/06/gan-basic/train_gan.png" alt="train_gan"><br>（<strong>GAN的完整训练过程</strong>。图片来自于“李宏毅 深度学习”课程）<br>(Ian Goodfellow, 在原始论文中改训练G为$-log(D(G(z)))$, 这个训练目标是从收敛的角度来考虑的)</p>
<h4 id="GAN的特别之处在哪里？"><a href="#GAN的特别之处在哪里？" class="headerlink" title="GAN的特别之处在哪里？"></a>GAN的特别之处在哪里？</h4><ul>
<li>ML的训练会可能很麻烦：采用显式的概率分布（模型空间可能不够准确）；采用隐式的概率推断会涉及比较复杂的方法</li>
<li>GAN提供了另外一种方案，它直接利用BP来优化概率分布距离的方法：求解generator和discriminator的minimax博弈。generator和discriminator都采用neural network，有足够强大的表征能力（给一个表征能力的实验）。</li>
<li>GAN提供了一个框架，可以将ML纳入进来，甚至可以按需设计其它的函数V（参见fGAN）</li>
</ul>
<p><strong>那么能否在GAN的框架下，将ML与原始GAN统一起来？能否使用其它的概率距离度量？</strong></p>
<h2 id="fGAN-GAN的统一框架"><a href="#fGAN-GAN的统一框架" class="headerlink" title="fGAN: GAN的统一框架"></a>fGAN: GAN的统一框架</h2><h3 id="f-divergency"><a href="#f-divergency" class="headerlink" title="f-divergency"></a>f-divergency</h3><p><strong>定义：</strong><br>$$D_f(P || Q) = \int_x q(x) f(\frac{p(x)}{q(x)})dx,\ 且f是convex, f(1)=0$$ </p>
<p><strong>例子：</strong></p>
<ul>
<li>$f = xlogx, D_f(P||Q) = KL(P||Q)$</li>
<li>$f = -logx, D_f(P||Q) = revserse\ KL(P||Q)$</li>
<li><p>$f=ulogu-(u+1)log(u+1), D_f(P||Q) =2JS(P||Q) - 2log2$</p>
</li>
<li><p>f=ulogu-(u+1)log(u+1), D_f(P||Q) =2JS(P||Q) - 2log2$</p>
</li>
</ul>
<h3 id="Fenchel-Conjugate"><a href="#Fenchel-Conjugate" class="headerlink" title="Fenchel Conjugate:"></a><strong>Fenchel Conjugate:</strong></h3><p>$$f^<em>(t) = \max\limits<em>{x \in Dom(f)} {xt-f(x)}$$<br>$$f(x) = \max\limits</em>{t \in Dom(f^</em>)} {xt-f^<em>(t)}$$<br>（注：$f^</em>(t)$也是convex, 它是一系列仿射函数的max）</p>
<p><strong>事实上，Fenchel Conjugate定义了“斜率（梯度）到截距”的一种映射</strong><br>当固定$t $,  $f^<em>(t) = \max\limits_{x \in Dom(f)} {xt-f(x)}$, 通过对x求导得到：$$t=  f’(x), \ f^</em>(t) = xf’(x) - f(x)$$<br>上式可以看做参数方程的形式定义了$f^<em>$，它的几何意义：对任意的x，作f(x)的切线，斜率为t, 与y的截距的负数为$f^</em>(t)$; 它定义了斜率和负截距的映射关系。</p>
<p><strong>重要的是，上述映射关系的对偶性质！</strong></p>
<h3 id="与GAN的联系"><a href="#与GAN的联系" class="headerlink" title="与GAN的联系"></a>与GAN的联系</h3><p>$$<br>    D_f(P||Q) = \int_x q(x) f(\frac{p(x)}{q(x)})dx\<br>    = \int<em>x q(x) \max\limits</em>{t\in dom(f^<em>)} { t\frac{p(x)}{q(x)} - f^</em>(t)} dx\<br>    \ge  \max\limits_{t\in dom(f^<em>)}  \int_x p(x)t dx -  \int_x q(x)f^</em>(t) dx<br>$$</p>
<p>这里，令D(x) = t, 上式的下界可以写作：<br>$$<br>     \max\limits_{D}  \int_x p(x)D(x)dx -  \int<em>x q(x)f^*(D(x)) dx \<br>     =  \max\limits</em>{D} { E<em>{x\sim p}[D(x)] - E</em>{x\sim q}[f^<em>(D(x))] }<br>$$<br>(事实上，如果D(x)表征能力足够强，最优解为$D^</em>(x) = f’(\frac{p(x)}{q(x)})$,但是这个无法直接求解 )<br>对于GAN而言：<br>$$<br>    D<em>f(P</em>{data}||P<em>{G})  \approx \max\limits</em>{D} { E<em>{x\sim P</em>{data}}[D(x)] - E_{x\sim P<em>G}[f^<em>(D(x))] }<br>$$<br>写成minimax形式：<br>$$ G^</em> = \arg \min\limits</em>{G}\max\limits_{D} V(G,D)$$</p>
<p><strong>按需挑选不同的f-divergency:</strong><br><img src="/2018/01/06/gan-basic/fgan_1.png" alt="fgan_1_"><br><img src="/2018/01/06/gan-basic/fgan_2.png" alt="fgan_2_"><br>(<strong>不同的f-divergency对应的GAN</strong>, 图片来自于论文 f-GAN)</p>
<h2 id="WGAN：解决收敛性问题"><a href="#WGAN：解决收敛性问题" class="headerlink" title="WGAN：解决收敛性问题"></a>WGAN：解决收敛性问题</h2><h3 id="origin-GAN面临的收敛问题"><a href="#origin-GAN面临的收敛问题" class="headerlink" title="origin-GAN面临的收敛问题"></a>origin-GAN面临的收敛问题</h3><p><strong>理想情况：D 指导$P<em>G$往真实分布$P</em>{data}$(dashed)运动</strong><br><img src="/2018/01/06/gan-basic/wgan_1.png" alt="fgan_1_"><br><strong>实际情况：D训练越好，完美区分，梯度消失，无指导能力</strong><br><img src="/2018/01/06/gan-basic/wgan_2.png" alt="fgan_2_"></p>
<p>考虑”parallel lines distribution”, 二维分布$P_{data}: (0, Z), 其中Z \sim U[0,1]$, $P_G: (\theta, Z)$:</p>
<ul>
<li>$JS(P_{data}, P_G) = |\theta|$</li>
<li>$KL(P_{data} || P_G) = KL(P<em>G || P</em>{data} ) = + \infty (\theta \ne 0), 0(\theta=0)$</li>
<li>Discriminator D往往能将$P_{data}, P_G$完美分开</li>
<li>如上图所示，在D看来，$d<em>0, d</em>{50}$的JSD都是log2; D没有动力，让$P_G$往“期望的方向”移动，会导致收敛问题</li>
<li>事实上，像生物进化一样，进化（比如眼睛）往往不是一蹴而就的；应该有更合适的度量方式，使得$P<em>G$向$P</em>{data}$“靠拢”（虽然此时JSD看来，generator并没有改善）</li>
</ul>
<h3 id="Earth-Mover’s-Distance"><a href="#Earth-Mover’s-Distance" class="headerlink" title="Earth Mover’s Distance"></a>Earth Mover’s Distance</h3><p><strong>定义：</strong>对于概率分布P,Q，average distance of a plan $\gamma$:<br>$$ B(\gamma) = \sum\limits_{x_p, x_q} \gamma(x_p, x_q) ||x_p, x<em>q|| $$<br>Earth Mover’s Distance:<br>$$ W(P,Q) = \min\limits</em>{\gamma \in \Pi} B(\gamma)$$<br>示意图如下：<br>本质上，$\gamma$就是一个联合概率，它的边缘分布分别为$P, Q$<br><img src="/2018/01/06/gan-basic/earth_mover.png" alt="earth_mover"><br>（<strong>Moving Plan</strong>, 图片来自于“李宏毅 深度学习”）<br>在上面的<strong>parallel line distribution</strong>例子里,</p>
<ul>
<li>$W(P_{data}, P_G) = |\theta|$</li>
</ul>
<h3 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h3><p>论文中证明，当我们采用Earth Mover’s Distance来度量$P_{data}, P<em>G$距离，相应的GAN形式如下(Kantorovich-Rubinstein duality, 来自论文“Optimal Transport: Old and New”)：<br>$$<br>    W(P</em>{data}, P<em>G) = \max\limits</em>{D \in 1-lipschitz} { E<em>{x\sim P</em>{data}}[D(x)] -  E<em>{x\sim P</em>{G}}[D(x)] }<br>$$<br>其中，<strong>1-lipschitz </strong>是指：<br>$$ ||D(x_1) - D(x_2)|| \le ||x_1 - x_2|| $$<br>该条件的限制，防止了D(x)的变化过于剧烈。这里，整个优化目标有点“返璞归真”的意思了。<br><strong>WGAN的论文中，使用weight-clipping近似1-lipschitz 条件</strong>：</p>
<ul>
<li>权重$|w| &gt; c \Rightarrow |w|=c$</li>
<li>实际使用的是<strong>k-lipschitz</strong><br><img src="/2018/01/06/gan-basic/wgan_3.png" alt="wgan_3_"></li>
<li>可以看到origin GAN 会存在梯度消失，无法有效指导$P_G$的方向</li>
<li>WGAN可以提供有效信息。</li>
<li>$W(P_{data}, P_G)$的值可以作为训练好坏的参考</li>
</ul>
<p><strong>improved WGAN</strong></p>
<p>将WGAN的1-lipschitz条件以惩罚项的形式引入：</p>
<p>​    $$W(P_{data}, P<em>G) = \max\limits</em>{D} { E<em>{x\sim P</em>{data}}[D(x)] -  E<em>{x\sim P</em>{G}}[D(x)] } - \lambda E<em>{x\sim P</em>{penalty}}[(||\nabla_x D(x)||-1)^2]$$</p>
<p>$P<em>{penalty}$的生成：对于$x \sim P</em>{data}, \tilde{x} \sim P<em>G$, 计算$x，\tilde{x}$之间的随机点，作为$x’ \sim P</em>{penalty}$</p>
<h3 id="GAN的家族"><a href="#GAN的家族" class="headerlink" title="GAN的家族"></a>GAN的家族</h3><table>
<thead>
<tr>
<th style="text-align:left">Modify the optimization of GAN</th>
<th style="text-align:right">Different structure from the original GAN</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">fGAN</td>
<td style="text-align:right">Conditional GAN</td>
</tr>
<tr>
<td style="text-align:left">WGAN</td>
<td style="text-align:right">Semi-GAN</td>
</tr>
<tr>
<td style="text-align:left">Least-square GAN</td>
<td style="text-align:right">InfoGAN</td>
</tr>
<tr>
<td style="text-align:left">Loss Sensitive GAN</td>
<td style="text-align:right">BiGAN</td>
</tr>
<tr>
<td style="text-align:left">Energy-based GAN</td>
<td style="text-align:right">Cycle GAN</td>
</tr>
<tr>
<td style="text-align:left">Boundary-Seeking GAN</td>
<td style="text-align:right">IRGAN</td>
</tr>
<tr>
<td style="text-align:left">Unroll GAN</td>
<td style="text-align:right">VAE GAN</td>
</tr>
<tr>
<td style="text-align:left">…</td>
<td style="text-align:right">…</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://luoxc.com/2018/01/06/gan-basic/" data-id="cjc3iqp5r0004u15dt10o8yla" class="article-share-link">Partager</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="../standard-varariable/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          特征标准化与条件数
        
      </div>
    </a>
  
  
    <a href="../../../../2017/12/31/auto-encoder/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">auto_encoder</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Catégories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="../../../../categories/人文的意义/">人文的意义</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/机器的理智/">机器的理智</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/琐碎的胜利/">琐碎的胜利</a></li><li class="category-list-item"><a class="category-list-link" href="../../../../categories/逻辑的引擎/">逻辑的引擎</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2018/01/">January 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/12/">December 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="../../../../archives/2017/02/">February 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Articles récents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="../standard-varariable/">特征标准化与条件数</a>
          </li>
        
          <li>
            <a href="">GAN的基本原理</a>
          </li>
        
          <li>
            <a href="../../../../2017/12/31/auto-encoder/">auto_encoder</a>
          </li>
        
          <li>
            <a href="../../../../2017/12/31/optimization/">最优化方法</a>
          </li>
        
          <li>
            <a href="../../../../2017/12/31/unbias-estimator/">无偏估计</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Finch Luo<br>
      Propulsé by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="../../../../index.html" class="mobile-nav-link">Home</a>
  
    <a href="../../../../archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="../../../../fancybox/jquery.fancybox.css">
  <script src="../../../../fancybox/jquery.fancybox.pack.js"></script>


<script src="../../../../js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>